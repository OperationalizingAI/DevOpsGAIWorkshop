{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create addtional embeddings in Atlas (for sample_mflix))\n",
        "## Using LLama Index"
      ],
      "metadata": {
        "id": "_Jni6zsUJ3Ah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">For Googla Colab Only\n",
        "\n",
        ">>git clone https://github.com/OperationalizingAI/Hackathon-2-22-24.gi"
      ],
      "metadata": {
        "id": "FPCoRhb3NMT6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC3_s3N8Fo0F"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Only Code"
      ],
      "metadata": {
        "id": "RdHGzW3D4oW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-secret-manager\n",
        "!pip install --upgrade google-auth\n",
        "\n",
        "import os\n",
        "\n",
        "from google.cloud import secretmanager\n",
        "from google.colab import auth\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "pozEcsdxIlxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_secrets(secrets_name, project_id):\n",
        "  # Build a client\n",
        "  auth.authenticate_user()\n",
        "  client = secretmanager.SecretManagerServiceClient()\n",
        "  secret_name = secrets_name\n",
        "  # Create path to latest secret\n",
        "  resource_name = f\"projects/{project_id}/secrets/{secret_name}/versions/latest\"\n",
        "  # Get your secret :\n",
        "  response = client.access_secret_version(request={\"name\": resource_name})\n",
        "  secret_string = response.payload.data.decode('UTF-8')\n",
        "  return secret_string"
      ],
      "metadata": {
        "id": "6Z1hF5x_IqlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'botchagalupep1'\n",
        "openai_api_key = load_secrets(\"openai_api_key\",project_id)\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "#MONGODB_ATLAS_CLUSTER_URI = load_secrets(\"mdb_uri\",project_id)\n",
        "MONGODB_ATLAS_CLUSTER_URI = load_secrets(\"MDB_CLUSTER0_URI\",project_id)\n",
        "langsmith_api_key = load_secrets(\"langsmith_api_key\",project_id)\n",
        "#print(langsmith_api_key )\n",
        "#print(MONGODB_ATLAS_CLUSTER_URI)"
      ],
      "metadata": {
        "id": "AxNeNGSqIywX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our variables\n",
        "\n",
        "DB_NAME = 'sample_mflix'\n",
        "COLLECTION_NAME = 'embedded_movies'"
      ],
      "metadata": {
        "id": "6qlYB5MXWPAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from AtlasClient import AtlasClient\n",
        "\n",
        "atlas_client = AtlasClient (MONGODB_ATLAS_CLUSTER_URI, DB_NAME)\n",
        "print(\"Connected to the Mongo Atlas database!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11tJ-hjWhIqW",
        "outputId": "756cbdbe-7213-4fe5-80e6-a627fbf35758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to the Mongo Atlas database!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collection = atlas_client.get_collection(COLLECTION_NAME)\n",
        "document_count = collection.count_documents({})\n",
        "\n",
        "print (f\"document count = {document_count:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NQd2DOTZ3Vg",
        "outputId": "fb2ebe33-dd64-447f-d30f-11b6a0152d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document count = 1,500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install llama-index-embeddings-huggingface\n",
        "%pip install llama-index-embeddings-instructor"
      ],
      "metadata": {
        "id": "5kMWl_qqWjG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "## LlamaIndex will download embeddings models as needed.\n",
        "## Set llamaindex cache dir to ./cache dir here (Default is system tmp)\n",
        "## This way, we can easily see downloaded artifacts\n",
        "os.environ['LLAMA_INDEX_CACHE_DIR'] = os.path.join(os.path.abspath(''), '..', 'llama-index-cache')"
      ],
      "metadata": {
        "id": "8ViU9jLWToCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "import time\n",
        "\n",
        "## handy function to calculate embeddings, given a model\n",
        "def create_embeddings (movies, embedding_model, embedding_attr):\n",
        "    embed_model = HuggingFaceEmbedding(model_name=embedding_model)\n",
        "\n",
        "    t2a = time.perf_counter()\n",
        "    for movie in movies:\n",
        "        movie[embedding_attr] = embed_model.get_text_embedding(movie['plot'])\n",
        "\n",
        "    t2b = time.perf_counter()\n",
        "    # print (f'Embeddings generated for {len(movies):,} movies  in {(t2b-t2a)*1000:,.0f} ms')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGnueEwgeJoZ",
        "outputId": "6b518a9d-32a8-4553-8ab8-b682fe9af462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /usr/local/lib/python3.10/dist-\n",
            "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /usr/local/lib/python3.10/dist-\n",
            "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch all movies\n",
        "t1a = time.perf_counter()\n",
        "movies = [m for m in atlas_client.find (collection_name=COLLECTION_NAME, filter={'plot':{\"$exists\": True}}, limit=0)]\n",
        "t1b = time.perf_counter()\n",
        "\n",
        "print (f'Fetched {len(movies):,} from Atlas in {(t1b-t1a)*1000:,.0f} ms')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doul3_ujeWw9",
        "outputId": "cad0074a-dbc5-431e-e91d-44c34cefc317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 1,500 from Atlas in 1,389 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Embedding models we want to use.\n",
        "\n",
        "model_mappings = {\n",
        "    'BAAI/bge-small-en-v1.5' : {'embedding_attr' : 'plot_embedding_bge_small', 'index_name' : 'idx_plot_embedding_bge_small'},\n",
        "\n",
        "    'sentence-transformers/all-mpnet-base-v2' : {'embedding_attr' : 'plot_embedding_mpnet_base_v2', 'index_name' : 'idx_plot_embedding_mpnet_base_v2'},\n",
        "\n",
        "    # 'sentence-transformers/all-MiniLM-L12-v2' : {'embedding_attr' : 'plot_embedding_minilm_l12_v2', 'index_name' : 'idx_plot_embedding_minilm_l12_v2'},\n",
        "\n",
        "    'sentence-transformers/all-MiniLM-L6-v2' : {'embedding_attr' : 'plot_embedding_minilm_l6_v2', 'index_name' : 'idx_plot_embedding_minilm_l6_v2'},\n",
        "\n",
        "    ## bge-large takes too long and consumes too much memory!\n",
        "    # 'BAAI/bge-large-en-v1.5' : {'embedding_attr' : 'plot_embedding_bge_large', 'index_name' : 'idx_plot_embedding_bge_large', 'embedding_length' : 1024},\n",
        "}"
      ],
      "metadata": {
        "id": "a44RPvJmecAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## For selected embedding models above, we are giong to create vectors\n",
        "## in movie collection.\n",
        "## Remember, each embedding model has its own 'plot_embedding' attribute (we don't want to mix them up)\n",
        "\n",
        "for key in model_mappings.keys():\n",
        "    embedding_model = key\n",
        "    embedding_attr = model_mappings[key]['embedding_attr']\n",
        "\n",
        "    print (f'\\n------- embedding model = {embedding_model} ---------')\n",
        "    t1a = time.perf_counter()\n",
        "    create_embeddings(movies=movies, embedding_model=embedding_model, embedding_attr=embedding_attr)\n",
        "    t1b = time.perf_counter()\n",
        "    avg_time_per_movie = (t1b-t1a)*1000 / len(movies)\n",
        "    print (f'model={embedding_model}, created embeddings for {len(movies):,} movies in {(t1b-t1a)*1000:,.0f} ms, avg_time_per_movie={avg_time_per_movie:,.0f} ms')"
      ],
      "metadata": {
        "id": "MzRga7q_efU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "movie = random.choice(movies)\n",
        "# print (movie)\n",
        "print ('_id :', movie['_id'])\n",
        "print ('title :', movie['title'])\n",
        "print ('plot :', movie['plot'])\n",
        "print (f'plot_embeddings (existing openAI generated), len={len(movie[\"plot_embedding\"])} , {movie[\"plot_embedding\"][:5]}...')\n",
        "print (f'plot_embedding_bge_small , len={len(movie[\"plot_embedding_bge_small\"])} , {movie[\"plot_embedding_bge_small\"][:5]}...')\n",
        "print (f'plot_embedding_mpnet_base_v2 , len={len(movie[\"plot_embedding_mpnet_base_v2\"])} , {movie[\"plot_embedding_mpnet_base_v2\"][:5]}...')\n",
        "print (f'plot_embedding_minilm_l6_v2 , len={len(movie[\"plot_embedding_minilm_l6_v2\"])} , {movie[\"plot_embedding_minilm_l6_v2\"][:5]}...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkMzz1anej4O",
        "outputId": "b67f8660-2e88-4ff2-c95b-a3cc3a5190ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_id : 65cb71579e5a3532351227dc\n",
            "title : D.E.B.S.\n",
            "plot : Plaid-skirted schoolgirls are groomed by a secret government agency to become the newest members of the elite national-defense group, D.E.B.S.\n",
            "plot_embeddings (existing openAI generated), len=1536 , [-0.027119491, -0.014553583, -0.008263821, -0.025921442, -0.017766535]...\n",
            "plot_embedding_bge_small , len=384 , [-0.06293287873268127, 0.03485560789704323, 0.02202887274324894, -0.04800337553024292, 0.07878005504608154]...\n",
            "plot_embedding_mpnet_base_v2 , len=768 , [0.01646951213479042, 0.010799586772918701, 0.02173537015914917, -0.01162173692137003, -0.00999673455953598]...\n",
            "plot_embedding_minilm_l6_v2 , len=384 , [-0.044605500996112823, 0.03230508416891098, 0.020126136019825935, -0.005326232872903347, 0.041450947523117065]...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's do a bulk update\n",
        "from pymongo import  ReplaceOne\n",
        "\n",
        "\n",
        "collection = atlas_client.get_collection(COLLECTION_NAME)\n",
        "\n",
        "replacements = [ReplaceOne ({\"_id\" : movie[\"_id\"]}, movie) for movie in movies]\n",
        "\n",
        "# print (replacements[:3])\n",
        "\n",
        "# Perform bulk replacement\n",
        "print (f'About to update {len(replacements)} movies in Atlas...')\n",
        "t1a = time.perf_counter()\n",
        "result = collection.bulk_write(replacements)\n",
        "t1b = time.perf_counter()\n",
        "\n",
        "## Print result\n",
        "print(f\"Update matched count: {result.matched_count}\")\n",
        "print(f\"Update modified count: {result.modified_count}\")\n",
        "print (f'Updated {len(movies):,} in Atlas in {(t1b-t1a)*1000:,.0f} ms')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smzUwlYGeqwk",
        "outputId": "470474fe-c32b-4e20-fccb-d7919a168039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "About to update 1500 movies in Atlas...\n",
            "Update matched count: 1500\n",
            "Update modified count: 1500\n",
            "Updated 1,500 in Atlas in 10,795 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to add three new Atlas Vector Indexes\n",
        "\n",
        "idx_plot_embedding_bge_small\n",
        "\n",
        "```\n",
        "{\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"type\": \"vector\",\n",
        "      \"path\": \"plot_embedding_bge_small\",\n",
        "      \"numDimensions\": 384,\n",
        "      \"similarity\": \"euclidean\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "idx_plot_embedding_mpnet_base_v2\n",
        "\n",
        "```\n",
        "{\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"type\": \"vector\",\n",
        "      \"path\": \"plot_embedding_mpnet_base_v2\",\n",
        "      \"numDimensions\": 768,\n",
        "      \"similarity\": \"euclidean\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "idx_plot_embedding_minilm_l6_v2\n",
        "\n",
        "```\n",
        "{\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"type\": \"vector\",\n",
        "      \"path\": \"plot_embedding_minilm_l6_v2\",\n",
        "      \"numDimensions\": 384,\n",
        "      \"similarity\": \"euclidean\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZuMjXxu4jW5D"
      }
    }
  ]
}