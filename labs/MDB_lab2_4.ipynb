{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ">For Googla Colab Only\n",
        "\n",
        ">>git clone https://github.com/OperationalizingAI/Hackathon-2-22-24.gi`\n"
      ],
      "metadata": {
        "id": "FPCoRhb3NMT6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC3_s3N8Fo0F"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Only Code"
      ],
      "metadata": {
        "id": "RdHGzW3D4oW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-secret-manager\n",
        "!pip install --upgrade google-auth\n",
        "\n",
        "import os\n",
        "\n",
        "from google.cloud import secretmanager\n",
        "from google.colab import auth\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "pozEcsdxIlxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_secrets(secrets_name, project_id):\n",
        "  # Build a client\n",
        "  auth.authenticate_user()\n",
        "  client = secretmanager.SecretManagerServiceClient()\n",
        "  secret_name = secrets_name\n",
        "  # Create path to latest secret\n",
        "  resource_name = f\"projects/{project_id}/secrets/{secret_name}/versions/latest\"\n",
        "  # Get your secret :\n",
        "  response = client.access_secret_version(request={\"name\": resource_name})\n",
        "  secret_string = response.payload.data.decode('UTF-8')\n",
        "  return secret_string"
      ],
      "metadata": {
        "id": "6Z1hF5x_IqlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'botchagalupep1'\n",
        "openai_api_key = load_secrets(\"openai_api_key\",project_id)\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "#MONGODB_ATLAS_CLUSTER_URI = load_secrets(\"mdb_uri\",project_id)\n",
        "MONGODB_ATLAS_CLUSTER_URI = load_secrets(\"MDB_CLUSTER0_URI\",project_id)\n",
        "langsmith_api_key = load_secrets(\"langsmith_api_key\",project_id)\n",
        "#print(langsmith_api_key )\n",
        "#print(MONGODB_ATLAS_CLUSTER_URI)"
      ],
      "metadata": {
        "id": "AxNeNGSqIywX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DB_NAME = 'langchain_db'\n",
        "COLLECTION_NAME = 'test'\n",
        "INDEX_NAME = 'vector_index'"
      ],
      "metadata": {
        "id": "6qlYB5MXWPAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from AtlasClient import AtlasClient\n",
        "\n",
        "atlas_client = AtlasClient (MONGODB_ATLAS_CLUSTER_URI, DB_NAME)\n",
        "print(\"Connected to the Mongo Atlas database!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11tJ-hjWhIqW",
        "outputId": "e56234b4-0e91-4353-a921-e893ee5082c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to the Mongo Atlas database!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from OpenAIClient import OpenAIClient\n",
        "\n",
        "openAI_client = None\n",
        "\n",
        "openAI_client = OpenAIClient (api_key=openai_api_key)\n",
        "print (\"OpenAI client initialized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9zFH47-vlOT",
        "outputId": "6d76215a-8db8-41d6-feff-ce764cc08eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI client initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "\n",
        "'What is GPT-4?',\n",
        "'What is GPT-3.5?',\n",
        "'What is GPT-3.5 in terms of capabilities?',\n",
        "'What is GPT-4 in terms of capabilities?'\n",
        "\n",
        "]\n"
      ],
      "metadata": {
        "id": "XUWy7P6Idze0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = {}\n",
        "\n",
        "for query in queries:\n",
        "    embedding  = openAI_client.get_embedding(query, model='text-embedding-ada-002')\n",
        "    print (f\"Embedding for query='{query}', embeddding_length={len(embedding)}, printing first few numbers... :\\n\", embedding [:10] )\n",
        "\n",
        "    embeddings[query] = embedding"
      ],
      "metadata": {
        "id": "rOGYYeV6dzUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "str = json.dumps(embeddings)\n",
        "\n",
        "with open(\"embeddings_openai.json\", \"w\") as f:\n",
        "    f.write(str)\n",
        "\n",
        "print (\"saved to : 'embeddings_openai.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I05iGVmqeCbO",
        "outputId": "c73a2e59-ff7e-4a36-836a-e27c1a030796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved to : 'embeddings_openai.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "cached_embeddings = {}\n",
        "cached_embedding_file = 'embeddings_openai.json'\n",
        "\n",
        "if os.path.exists(cached_embedding_file):\n",
        "    with open(cached_embedding_file, \"r\") as f:\n",
        "        str = f.read()\n",
        "        cached_embeddings = json.loads(str)\n",
        "\n",
        "print (\"Loaded the following cached embeddings...\")\n",
        "for query in cached_embeddings.keys():\n",
        "    print (f'- {query}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UlshjGscvdn",
        "outputId": "82f47283-50dc-486c-b9f0-5d5f023cff90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the following cached embeddings...\n",
            "- What is GPT-4?\n",
            "- What is GPT-3.5?\n",
            "- What is GPT-3.5 in terms of capabilities?\n",
            "- What is GPT-4 in terms of capabilities?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to update AtlasClient.py to include 'text' : 1"
      ],
      "metadata": {
        "id": "Z2oKs6n4-MJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Handy function\n",
        "def do_vector_search (query:str) -> None:\n",
        "    query = query.lower().strip()\n",
        "    print ('query: ', query)\n",
        "    if query in cached_embeddings.keys():\n",
        "        print (\"using cached embeddings\")\n",
        "        embedding = cached_embeddings.get (query)\n",
        "    else:\n",
        "        t1a = time.perf_counter()\n",
        "        embedding = openAI_client.get_embedding(query)\n",
        "        print(embedding)\n",
        "        t1b = time.perf_counter()\n",
        "        print (f\"Getting embeddings from OpenAI took {(t1b-t1a)*1000:,.0f} ms\")\n",
        "\n",
        "    t2a = time.perf_counter()\n",
        "    chunks = atlas_client.vector_search(collection_name=COLLECTION_NAME, index_name=INDEX_NAME, attr_name='embedding',embedding_vector=embedding,limit=10 )\n",
        "    t2b = time.perf_counter()\n",
        "\n",
        "    print (f\"Altas query returned {len (chunks)} movies in {(t2b-t2a)*1000:,.0f} ms\")\n",
        "\n",
        "    for idx, chunk in enumerate (chunks):\n",
        "         print(f'{idx+1}\\nid: {chunk[\"_id\"]}\\ntext: {chunk[\"text\"]}' +\n",
        "         f'\\nsearch_score(meta):{chunk[\"search_score\"]}n')"
      ],
      "metadata": {
        "id": "bBf7G8T0eRMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"What is GPT-4?\"\n",
        "\n",
        "do_vector_search (query=query)"
      ],
      "metadata": {
        "id": "6mxcwubzeiAg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}