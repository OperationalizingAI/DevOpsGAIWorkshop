{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vjgl2OTC_r_tYNa7hnNwp7sfIPMde9e2","timestamp":1709952647262},{"file_id":"1gMGVSHvrHDh8Mf3okBAyK8JMEJJKE4lU","timestamp":1708972784256},{"file_id":"1tRDG7JrUiqRAJOQShKk_3hDNZvOpqN2T","timestamp":1705687451345}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Evaluation of OpenContext Documentaion with Arize"],"metadata":{"id":"6Yi1T3_JH1ay"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sl3lgsKvh47O"},"outputs":[],"source":["%pip install --quiet langchain pypdf pymongo langchain-openai tiktoken google-cloud-secret-manager"]},{"cell_type":"code","source":["%pip install --upgrade google-auth"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A48y0kGZcaGd","executionInfo":{"status":"ok","timestamp":1709939250513,"user_tz":480,"elapsed":13824,"user":{"displayName":"Xander Song","userId":"01199918820069764064"}},"outputId":"ea342f87-5f26-4f37-a54e-f1472d01b8ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.28.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.5.1)\n"]}]},{"cell_type":"code","source":["import os\n","\n","%pip show langchain\n","\n","from platform import python_version\n","print(python_version())"],"metadata":{"id":"WlkitefoiJ24","executionInfo":{"status":"ok","timestamp":1709939263934,"user_tz":480,"elapsed":13424,"user":{"displayName":"Xander Song","userId":"01199918820069764064"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1e4e6a3f-2feb-4218-f261-556de8416296"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: langchain\n","Version: 0.1.11\n","Summary: Building applications with LLMs through composability\n","Home-page: https://github.com/langchain-ai/langchain\n","Author: \n","Author-email: \n","License: MIT\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: aiohttp, async-timeout, dataclasses-json, jsonpatch, langchain-community, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n","Required-by: \n","3.10.12\n"]}]},{"cell_type":"code","source":["!pip install arize-phoenix"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRd6LDTiFidh","executionInfo":{"status":"ok","timestamp":1709939375870,"user_tz":480,"elapsed":111940,"user":{"displayName":"Xander Song","userId":"01199918820069764064"}},"outputId":"a4d966a9-0172-4882-c779-ac782e0a0eab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting arize-phoenix\n","  Using cached arize_phoenix-3.9.0-py3-none-any.whl (1.2 MB)\n","Collecting ddsketch (from arize-phoenix)\n","  Downloading ddsketch-2.0.4-py3-none-any.whl (18 kB)\n","Collecting hdbscan<1.0.0,>=0.8.33 (from arize-phoenix)\n","  Downloading hdbscan-0.8.33.tar.gz (5.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (3.1.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.25.2)\n","Collecting openinference-instrumentation-langchain>=0.1.11 (from arize-phoenix)\n","  Downloading openinference_instrumentation_langchain-0.1.11-py3-none-any.whl (13 kB)\n","Collecting openinference-instrumentation-llama-index>=1.1.1 (from arize-phoenix)\n","  Downloading openinference_instrumentation_llama_index-1.1.1-py3-none-any.whl (15 kB)\n","Collecting openinference-instrumentation-openai>=0.1.3 (from arize-phoenix)\n","  Downloading openinference_instrumentation_openai-0.1.3-py3-none-any.whl (21 kB)\n","Collecting openinference-semantic-conventions>=0.1.5 (from arize-phoenix)\n","  Downloading openinference_semantic_conventions-0.1.5-py3-none-any.whl (8.4 kB)\n","Collecting opentelemetry-exporter-otlp (from arize-phoenix)\n","  Downloading opentelemetry_exporter_otlp-1.23.0-py3-none-any.whl (7.0 kB)\n","Collecting opentelemetry-proto (from arize-phoenix)\n","  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-sdk (from arize-phoenix)\n","  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.5.3)\n","Requirement already satisfied: protobuf<5.0,>=3.20 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (3.20.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (5.9.5)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (14.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (2.31.0)\n","Requirement already satisfied: scikit-learn<1.3.0 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.11.4)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (2.4.0)\n","Collecting starlette (from arize-phoenix)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting strawberry-graphql==0.208.2 (from arize-phoenix)\n","  Downloading strawberry_graphql-0.208.2-py3-none-any.whl (269 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.0/269.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (4.10.0)\n","Collecting umap-learn (from arize-phoenix)\n","  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting uvicorn (from arize-phoenix)\n","  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.14.1)\n","Collecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.208.2->arize-phoenix)\n","  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.208.2->arize-phoenix) (2.8.2)\n","Collecting cython<3,>=0.27 (from hdbscan<1.0.0,>=0.8.33->arize-phoenix)\n","  Using cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan<1.0.0,>=0.8.33->arize-phoenix) (1.3.2)\n","Collecting opentelemetry-api (from openinference-instrumentation-langchain>=0.1.11->arize-phoenix)\n","  Downloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-instrumentation (from openinference-instrumentation-langchain>=0.1.11->arize-phoenix)\n","  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n","Collecting opentelemetry-semantic-conventions (from openinference-instrumentation-langchain>=0.1.11->arize-phoenix)\n","  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3.0->arize-phoenix) (3.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ddsketch->arize-phoenix) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->arize-phoenix) (2.1.5)\n","Collecting opentelemetry-exporter-otlp-proto-grpc==1.23.0 (from opentelemetry-exporter-otlp->arize-phoenix)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n","Collecting opentelemetry-exporter-otlp-proto-http==1.23.0 (from opentelemetry-exporter-otlp->arize-phoenix)\n","  Downloading opentelemetry_exporter_otlp_proto_http-1.23.0-py3-none-any.whl (16 kB)\n","Collecting deprecated>=1.2.6 (from opentelemetry-exporter-otlp-proto-grpc==1.23.0->opentelemetry-exporter-otlp->arize-phoenix)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.23.0->opentelemetry-exporter-otlp->arize-phoenix) (1.62.0)\n","Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.23.0->opentelemetry-exporter-otlp->arize-phoenix) (1.62.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc==1.23.0->opentelemetry-exporter-otlp->arize-phoenix)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n","Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api->openinference-instrumentation-langchain>=0.1.11->arize-phoenix)\n","  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->arize-phoenix) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->arize-phoenix) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->arize-phoenix) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->arize-phoenix) (2024.2.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->arize-phoenix) (2023.4)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->arize-phoenix) (3.7.1)\n","Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn->arize-phoenix) (0.58.1)\n","Collecting pynndescent>=0.5 (from umap-learn->arize-phoenix)\n","  Downloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->arize-phoenix) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->arize-phoenix) (0.14.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->arize-phoenix) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->arize-phoenix) (1.2.0)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn->arize-phoenix) (0.41.1)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation->openinference-instrumentation-langchain>=0.1.11->arize-phoenix) (67.7.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api->openinference-instrumentation-langchain>=0.1.11->arize-phoenix) (3.17.0)\n","Building wheels for collected packages: hdbscan, umap-learn\n","  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdbscan: filename=hdbscan-0.8.33-cp310-cp310-linux_x86_64.whl size=3039286 sha256=f05e5fbc16067ca2b2cabb21ebd064a94b15cd4dc3bf952fa06a70dc5a39fd97\n","  Stored in directory: /root/.cache/pip/wheels/75/0b/3b/dc4f60b7cc455efaefb62883a7483e76f09d06ca81cf87d610\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86832 sha256=057912264815fb2e84e7ea8aa2f1148d6259177f6526f8258923a8ad061de23b\n","  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n","Successfully built hdbscan umap-learn\n","Installing collected packages: uvicorn, opentelemetry-semantic-conventions, opentelemetry-proto, openinference-semantic-conventions, importlib-metadata, graphql-core, deprecated, ddsketch, cython, strawberry-graphql, starlette, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, pynndescent, opentelemetry-sdk, opentelemetry-instrumentation, hdbscan, umap-learn, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openinference-instrumentation-openai, openinference-instrumentation-llama-index, openinference-instrumentation-langchain, opentelemetry-exporter-otlp, arize-phoenix\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 7.0.1\n","    Uninstalling importlib-metadata-7.0.1:\n","      Successfully uninstalled importlib-metadata-7.0.1\n","  Attempting uninstall: cython\n","    Found existing installation: Cython 3.0.9\n","    Uninstalling Cython-3.0.9:\n","      Successfully uninstalled Cython-3.0.9\n","Successfully installed arize-phoenix-3.9.0 cython-0.29.37 ddsketch-2.0.4 deprecated-1.2.14 graphql-core-3.2.3 hdbscan-0.8.33 importlib-metadata-6.11.0 openinference-instrumentation-langchain-0.1.11 openinference-instrumentation-llama-index-1.1.1 openinference-instrumentation-openai-0.1.3 openinference-semantic-conventions-0.1.5 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-exporter-otlp-proto-http-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 pynndescent-0.5.11 starlette-0.37.2 strawberry-graphql-0.208.2 umap-learn-0.5.5 uvicorn-0.27.1\n"]}]},{"cell_type":"code","source":["from urllib.request import urlopen\n","\n","import nest_asyncio\n","import numpy as np\n","import pandas as pd\n","import phoenix as px\n","from langchain.chains import RetrievalQA\n","from langchain.chat_models import ChatOpenAI\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.retrievers import KNNRetriever\n","from phoenix.experimental.evals import (\n","    HallucinationEvaluator,\n","    OpenAIModel,\n","    QAEvaluator,\n","    RelevanceEvaluator,\n","    run_evals,\n",")\n","from phoenix.session.evaluation import get_qa_with_reference, get_retrieved_documents\n","from phoenix.trace import DocumentEvaluations, SpanEvaluations\n","from phoenix.trace.langchain import LangChainInstrumentor\n","from tqdm import tqdm\n","\n","nest_asyncio.apply()  # needed for concurrent evals in notebook environments"],"metadata":{"id":"mDx-ckXTFtSf","executionInfo":{"status":"ok","timestamp":1709939410058,"user_tz":480,"elapsed":34197,"user":{"displayName":"Xander Song","userId":"01199918820069764064"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5aa5994d-9d41-4598-8d3a-6d96cb1c9790"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:phoenix.experimental.evals:Evals are moving out of experimental. Install the evals extra with `pip install arize-phoenix[evals]` and import `phoenix.evals`. For more info, see the [migration guide](https://github.com/Arize-ai/phoenix/blob/main/MIGRATION.md).\n"]}]},{"cell_type":"code","source":["import os\n","from google.cloud import secretmanager\n","from google.colab import auth\n","from google.colab import drive"],"metadata":{"id":"5Ca6p8tnd-wL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#drive.mount('/content/gdrive')"],"metadata":{"id":"r3S2IMoa2e07"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_secrets(secrets_name, project_id):\n","  # Build a client\n","  auth.authenticate_user()\n","  client = secretmanager.SecretManagerServiceClient()\n","  secret_name = secrets_name\n","  # Create path to latest secret\n","  resource_name = f\"projects/{project_id}/secrets/{secret_name}/versions/latest\"\n","  # Get your secret :\n","  response = client.access_secret_version(request={\"name\": resource_name})\n","  secret_string = response.payload.data.decode('UTF-8')\n","  return secret_string"],"metadata":{"id":"sCa55hgW2ikm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_id = 'botchagalupep1'\n","openai_api_key = load_secrets(\"openai_api_key\",project_id)\n","os.environ['OPENAI_API_KEY'] = openai_api_key\n","MONGODB_ATLAS_CLUSTER_URI = load_secrets(\"MDB_CLUSTER0_URI\",project_id)\n","langsmith_api_key = load_secrets(\"langsmith_api_key\",project_id)"],"metadata":{"id":"mWn3YgC12nlg","executionInfo":{"status":"error","timestamp":1709939514967,"user_tz":480,"elapsed":104634,"user":{"displayName":"Xander Song","userId":"01199918820069764064"}},"colab":{"base_uri":"https://localhost:8080/","height":512},"outputId":"31335bcb-3755-46b4-ad46-4f53ab5e8e7a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"PermissionDenied","evalue":"403 Permission 'secretmanager.versions.access' denied for resource 'projects/botchagalupep1/secrets/openai_api_key/versions/latest' (or it may not exist).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         )\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Permission 'secretmanager.versions.access' denied for resource 'projects/botchagalupep1/secrets/openai_api_key/versions/latest' (or it may not exist).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:74.125.139.95:443 {grpc_message:\"Permission \\'secretmanager.versions.access\\' denied for resource \\'projects/botchagalupep1/secrets/openai_api_key/versions/latest\\' (or it may not exist).\", grpc_status:7, created_time:\"2024-03-08T23:11:54.541456971+00:00\"}\"\n>","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-b0fa0cbaccc7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mproject_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'botchagalupep1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mopenai_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_secrets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"openai_api_key\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OPENAI_API_KEY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai_api_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMONGODB_ATLAS_CLUSTER_URI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_secrets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MDB_CLUSTER0_URI\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlangsmith_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_secrets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"langsmith_api_key\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-981d69ef8e97>\u001b[0m in \u001b[0;36mload_secrets\u001b[0;34m(secrets_name, project_id)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mresource_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"projects/{project_id}/secrets/{secret_name}/versions/latest\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# Get your secret :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccess_secret_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0msecret_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msecret_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/secretmanager_v1/services/secret_manager_service/client.py\u001b[0m in \u001b[0;36maccess_secret_version\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1768\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPermissionDenied\u001b[0m: 403 Permission 'secretmanager.versions.access' denied for resource 'projects/botchagalupep1/secrets/openai_api_key/versions/latest' (or it may not exist)."]}]},{"cell_type":"code","source":["# connect notebook to langsmith\n","os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n","os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n","\n","# This key is sourced from vars.env\n","os.environ['LANGCHAIN_API_KEY'] = langsmith_api_key  # Uncomment and replace  with your actual API key\n","\n","os.environ['LANGCHAIN_PROJECT'] = 'opencontext-1'\n","\n","# To verify, you can print the variables\n","print(os.environ.get('LANGCHAIN_TRACING_V2'))\n","print(os.environ.get('LANGCHAIN_ENDPOINT'))\n","#print(os.environ.get('LANGCHAIN_API_KEY'))  # Uncomment if you want to print your API key (be careful with sharing your notebook)\n","print(os.environ.get('LANGCHAIN_PROJECT'))"],"metadata":{"id":"NpU8CL2r22vD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pymongo import MongoClient\n","\n","# initialize MongoDB python client\n","client = MongoClient(MONGODB_ATLAS_CLUSTER_URI)\n","\n","DB_NAME = \"Cluster0\"\n","COLLECTION_NAME = \"OpenContext0\"\n","ATLAS_VECTOR_SEARCH_INDEX_NAME = \"vector_index\"\n","\n","MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]"],"metadata":{"id":"aPqh0syziQ2k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.vectorstores import MongoDBAtlasVectorSearch\n","from langchain_openai import OpenAIEmbeddings\n","\n","vector_search = MongoDBAtlasVectorSearch.from_connection_string(\n","    MONGODB_ATLAS_CLUSTER_URI,\n","    DB_NAME + \".\" + COLLECTION_NAME,\n","    OpenAIEmbeddings(model=\"text-embedding-3-small\",dimensions=1536,disallowed_special=()),\n","    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",")"],"metadata":{"id":"7himXISricVE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Similarity Search with Score"],"metadata":{"id":"jddBa70YjpAt"}},{"cell_type":"code","source":["px.close_app()\n","session = px.launch_app()\n","LangChainInstrumentor().instrument()"],"metadata":{"id":"dYv2b5P1F95o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"LJAL5t9N0uqa"}},{"cell_type":"markdown","source":[],"metadata":{"id":"8fsP9JtfWkqB"}},{"cell_type":"markdown","source":["#Question Answering"],"metadata":{"id":"43GA0yPQjw6T"}},{"cell_type":"markdown","source":["## https://github.com/Arize-ai/phoenix/tree/main/tutorials"],"metadata":{"id":"GUyp708odpt8"}},{"cell_type":"markdown","source":["# Use this example to evaluate your model"],"metadata":{"id":"MbmCqoDzKEtA"}},{"cell_type":"code","source":["queries = [\n","    'What is a CodeCompnent',\n","    'What is a SaaS User',\n","    'What is a Service',\n","    'What is a Location',\n","    'What is a Datacenter',\n","    'List all the entities',\n","    'List code examples',\n","    'List yaml examples names',\n","    'list the yaml example crates-erp'\n","]\n","\n","from langchain.chat_models import ChatOpenAI\n","\n","llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0, max_tokens=5000)\n","\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm, retriever=vector_search.as_retriever(), return_source_documents=True)\n","\n","for query in queries:\n","  answer = qa_chain({\"query\": query})\n","  print(\"Query:\", answer['query'])\n","  print(\"Result:\", answer['result'])"],"metadata":{"id":"GJYM9rSm1CWm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["queries_df = get_qa_with_reference(px.Client())\n","retrieved_documents_df = get_retrieved_documents(px.Client())"],"metadata":{"id":"wlBbSyHyQ1Fy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eval_model = OpenAIModel(\n","    model_name=\"gpt-4-turbo-preview\",\n",")\n","hallucination_evaluator = HallucinationEvaluator(eval_model)\n","qa_correctness_evaluator = QAEvaluator(eval_model)\n","relevance_evaluator = RelevanceEvaluator(eval_model)\n","\n","hallucination_eval_df, qa_correctness_eval_df = run_evals(\n","    dataframe=queries_df,\n","    evaluators=[hallucination_evaluator, qa_correctness_evaluator],\n","    provide_explanation=True,\n",")\n","relevance_eval_df = run_evals(\n","    dataframe=retrieved_documents_df,\n","    evaluators=[relevance_evaluator],\n","    provide_explanation=True,\n",")[0]\n","\n","px.Client().log_evaluations(\n","    SpanEvaluations(eval_name=\"Hallucination\", dataframe=hallucination_eval_df),\n","    SpanEvaluations(eval_name=\"QA Correctness\", dataframe=qa_correctness_eval_df),\n","    DocumentEvaluations(eval_name=\"Relevance\", dataframe=relevance_eval_df),\n",")"],"metadata":{"id":"Tr_nRl46RCg5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["px.Client().get_evaluations()\n"],"metadata":{"id":"nOxOVwKJ-l7Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trace_df = px.Client().get_spans_dataframe()\n","trace_df"],"metadata":{"id":"llFZb_OC0xoT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from phoenix.trace.dsl import SpanQuery\n","\n","query_for_root_span = SpanQuery().where(\n","    \"parent_id is None\",   # Filter for root spans\n",").select(\n","    input=\"input.value\",   # Input contains the user's question\n","    output=\"output.value\", # Output contains the LLM's answer\n",")\n","\n","query_for_retrieved_documents = SpanQuery().where(\n","    \"span_kind == 'RETRIEVER'\",  # Filter for RETRIEVER span\n",").select(\n","    # Rename parent_id as span_id. This turns the parent_id\n","    # values into the index of the output dataframe.\n","    span_id=\"parent_id\",\n",").concat(\n","    \"retrieval.documents\",\n","    reference=\"document.content\",\n",")\n","\n","# Perform an inner join on the two sets of spans.\n","pd.concat(\n","    px.Client().query_spans(\n","        query_for_root_span,\n","        query_for_retrieved_documents,\n","    ),\n","    axis=1,\n","    join=\"inner\",\n",")"],"metadata":{"id":"oLXsPkkX02FA"},"execution_count":null,"outputs":[]}]}