{"cells":[{"cell_type":"markdown","source":["<center>\n","    <p style=\"text-align:center\">\n","        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/phoenix-logo-light.svg\" width=\"200\"/>\n","        <br>\n","        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n","        |\n","        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n","        |\n","        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n","    </p>\n","</center>\n","<h1 align=\"center\">Tracing and Evaluating a LlamaIndex Application using MongoDB Atlas as Vector Store</h1>\n","\n","<h2 align=\"center\"> LAM Stack (LlamaIndex, Arize and MongoDB) </h2>\n","\n","LlamaIndex provides high-level APIs that enable users to build powerful applications in a few lines of code. However, it can be challenging to understand what is going on under the hood and to pinpoint the cause of issues. Phoenix makes your LLM applications *observable* by visualizing the underlying structure of each call to your query engine and surfacing problematic `spans`` of execution based on latency, token count, or other evaluation metrics.\n","\n","In this tutorial, you will:\n","- Generate data into a MongoDB Collection to be later used as a Vector Store.\n","- Build a simple query engine using LlamaIndex that uses retrieval-augmented generation to answer questions over the Arize documentation,\n","- Record trace data in [OpenInference tracing](https://github.com/Arize-ai/open-inference-spec/blob/main/trace/spec/traces.md) format using the global `arize_phoenix` handler\n","- Inspect the traces and spans of your application to identify sources of latency and cost,\n","- Export your trace data as a pandas dataframe and run an [LLM Evals](https://docs.arize.com/phoenix/concepts/llm-evals) to measure the precision@k of the query engine's retrieval step.\n","\n","癸 This notebook requires an OpenAI API key."],"metadata":{"id":"NqjcGG9QJhUJ"},"id":"NqjcGG9QJhUJ"},{"cell_type":"markdown","source":["## 1. Install needed dependencies and import relevant packages"],"metadata":{"id":"qtPye6KSKNrO"},"id":"qtPye6KSKNrO"},{"cell_type":"code","execution_count":null,"id":"66f1181a-67fb-4aab-b469-40f952ac5ea6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66f1181a-67fb-4aab-b469-40f952ac5ea6","outputId":"287382cf-0073-4aa2-bab0-660b445a561d","executionInfo":{"status":"ok","timestamp":1710359916925,"user_tz":420,"elapsed":148281,"user":{"displayName":"John Willis","userId":"15271974867993570949"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-index-embeddings-openai\n","  Downloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n","Collecting arize-phoenix\n","  Downloading arize_phoenix-3.13.1-py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-index\n","  Downloading llama_index-0.10.19-py3-none-any.whl (5.6 kB)\n","Collecting llama-index-callbacks-arize-phoenix\n","  Downloading llama_index_callbacks_arize_phoenix-0.1.4-py3-none-any.whl (2.0 kB)\n","Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Collecting install\n","  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n","Collecting llama-index-vector-stores-mongodb\n","  Downloading llama_index_vector_stores_mongodb-0.1.4-py3-none-any.whl (4.0 kB)\n","Collecting llama-index-storage-docstore-mongodb\n","  Downloading llama_index_storage_docstore_mongodb-0.1.2-py3-none-any.whl (2.2 kB)\n","Collecting llama-index-storage-index-store-mongodb\n","  Downloading llama_index_storage_index_store_mongodb-0.1.2-py3-none-any.whl (2.1 kB)\n","Collecting llama-index-readers-mongodb\n","  Downloading llama_index_readers_mongodb-0.1.3-py3-none-any.whl (2.8 kB)\n","Collecting openai>=1\n","  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gcsfs in /usr/local/lib/python3.10/dist-packages (2023.6.0)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n","Collecting pymongo\n","  Downloading pymongo-4.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m677.2/677.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (2024.2.2)\n","Collecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-embeddings-openai)\n","  Downloading llama_index_core-0.10.19-py3-none-any.whl (15.3 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ddsketch (from arize-phoenix)\n","  Downloading ddsketch-2.0.4-py3-none-any.whl (18 kB)\n","Collecting hdbscan<1.0.0,>=0.8.33 (from arize-phoenix)\n","  Downloading hdbscan-0.8.33.tar.gz (5.2 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (3.1.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.25.2)\n","Collecting openinference-instrumentation-langchain>=0.1.12 (from arize-phoenix)\n","  Downloading openinference_instrumentation_langchain-0.1.12-py3-none-any.whl (13 kB)\n","Collecting openinference-instrumentation-llama-index>=1.2.0 (from arize-phoenix)\n","  Downloading openinference_instrumentation_llama_index-1.2.0-py3-none-any.whl (15 kB)\n","Collecting openinference-instrumentation-openai>=0.1.4 (from arize-phoenix)\n","  Downloading openinference_instrumentation_openai-0.1.4-py3-none-any.whl (21 kB)\n","Collecting openinference-semantic-conventions>=0.1.5 (from arize-phoenix)\n","  Downloading openinference_semantic_conventions-0.1.5-py3-none-any.whl (8.4 kB)\n","Collecting opentelemetry-exporter-otlp (from arize-phoenix)\n","  Downloading opentelemetry_exporter_otlp-1.23.0-py3-none-any.whl (7.0 kB)\n","Collecting opentelemetry-proto (from arize-phoenix)\n","  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-sdk (from arize-phoenix)\n","  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.5.3)\n","Requirement already satisfied: protobuf<5.0,>=3.20 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (3.20.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (5.9.5)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (14.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (2.31.0)\n","Requirement already satisfied: scikit-learn<1.3.0 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.11.4)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (2.4.0)\n","Collecting starlette (from arize-phoenix)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting strawberry-graphql==0.208.2 (from arize-phoenix)\n","  Downloading strawberry_graphql-0.208.2-py3-none-any.whl (269 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m269.0/269.0 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (4.10.0)\n","Collecting umap-learn (from arize-phoenix)\n","  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting uvicorn (from arize-phoenix)\n","  Downloading uvicorn-0.28.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from arize-phoenix) (1.14.1)\n","Collecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.208.2->arize-phoenix)\n","  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.208.2->arize-phoenix) (2.8.2)\n","Collecting llama-index-agent-openai<0.2.0,>=0.1.4 (from llama-index)\n","  Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n","Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_cli-0.1.9-py3-none-any.whl (25 kB)\n","Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_indices_managed_llama_cloud-0.1.4-py3-none-any.whl (6.6 kB)\n","Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n","  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.5 (from llama-index)\n","  Downloading llama_index_llms_openai-0.1.9-py3-none-any.whl (10.0 kB)\n","Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n","  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n","Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n","  Downloading llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n","Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n","Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n","  Downloading llama_index_readers_file-0.1.9-py3-none-any.whl (35 kB)\n","Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n","Collecting llama-index-storage-kvstore-mongodb<0.2.0,>=0.1.1 (from llama-index-storage-docstore-mongodb)\n","  Downloading llama_index_storage_kvstore_mongodb-0.1.2-py3-none-any.whl (3.2 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai>=1)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1) (2.6.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1) (1.3.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (3.9.3)\n","Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (4.4.2)\n","Requirement already satisfied: fsspec==2023.6.0 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2023.6.0)\n","Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs) (1.2.0)\n","Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.8.0)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n","  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (4.0.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1) (1.2.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs) (4.9)\n","Collecting cython<3,>=0.27 (from hdbscan<1.0.0,>=0.8.33->arize-phoenix)\n","  Using cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan<1.0.0,>=0.8.33->arize-phoenix) (1.3.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1)\n","  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.1)\n","Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.28)\n","Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai)\n","  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n","Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai)\n","  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n","Collecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai)\n","  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.2.1)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.8.1)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (9.4.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.2.3)\n","Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai)\n","  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n","Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading PyMuPDF-1.23.26-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n","Collecting llama-parse<0.4.0,>=0.3.3 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n","  Downloading llama_parse-0.3.9-py3-none-any.whl (6.8 kB)\n","Collecting opentelemetry-api (from openinference-instrumentation-langchain>=0.1.12->arize-phoenix)\n","  Downloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-instrumentation (from openinference-instrumentation-langchain>=0.1.12->arize-phoenix)\n","  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n","Collecting opentelemetry-semantic-conventions (from openinference-instrumentation-langchain>=0.1.12->arize-phoenix)\n","  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1) (2.16.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->arize-phoenix) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->arize-phoenix) (2.0.7)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3.0->arize-phoenix) (3.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ddsketch->arize-phoenix) (1.16.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs) (1.4.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.11.1)\n","Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.3.3)\n","Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.7.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->arize-phoenix) (2.1.5)\n","Collecting opentelemetry-exporter-otlp-proto-grpc==1.23.0 (from opentelemetry-exporter-otlp->arize-phoenix)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n","Collecting opentelemetry-exporter-otlp-proto-http==1.23.0 (from opentelemetry-exporter-otlp->arize-phoenix)\n","  Downloading opentelemetry_exporter_otlp_proto_http-1.23.0-py3-none-any.whl (16 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.23.0->opentelemetry-exporter-otlp->arize-phoenix) (1.63.0)\n","Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.23.0->opentelemetry-exporter-otlp->arize-phoenix) (1.62.1)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc==1.23.0->opentelemetry-exporter-otlp->arize-phoenix)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n","Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api->openinference-instrumentation-langchain>=0.1.12->arize-phoenix)\n","  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->arize-phoenix) (2023.4)\n","Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn->arize-phoenix) (0.58.1)\n","Collecting pynndescent>=0.5 (from umap-learn->arize-phoenix)\n","  Downloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->arize-phoenix) (8.1.7)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->gcsfs) (1.5.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.12.25)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn->arize-phoenix) (0.41.1)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.5.1)\n","Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.0.3)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai)\n","  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation->openinference-instrumentation-langchain>=0.1.12->arize-phoenix) (67.7.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api->openinference-instrumentation-langchain>=0.1.12->arize-phoenix) (3.17.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (24.0)\n","Building wheels for collected packages: hdbscan, umap-learn\n","  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdbscan: filename=hdbscan-0.8.33-cp310-cp310-linux_x86_64.whl size=3039282 sha256=1f151e964ae565c8913884f033d1348d56add2674e108407f17f7aa9093a1152\n","  Stored in directory: /root/.cache/pip/wheels/75/0b/3b/dc4f60b7cc455efaefb62883a7483e76f09d06ca81cf87d610\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86832 sha256=64c8da2d9444a8fd13d2d4cee1f128ab2239d403eb47b7500577c33c625ab6a0\n","  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n","Successfully built hdbscan umap-learn\n","Installing collected packages: striprtf, dirtyjson, pypdf, PyMuPDFb, opentelemetry-semantic-conventions, opentelemetry-proto, openinference-semantic-conventions, mypy-extensions, marshmallow, install, importlib-metadata, h11, graphql-core, dnspython, deprecated, ddsketch, cython, uvicorn, typing-inspect, tiktoken, strawberry-graphql, starlette, pymupdf, pymongo, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, httpcore, bs4, pynndescent, opentelemetry-sdk, opentelemetry-instrumentation, httpx, hdbscan, dataclasses-json, umap-learn, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openinference-instrumentation-openai, openinference-instrumentation-llama-index, openinference-instrumentation-langchain, openai, llamaindex-py-client, opentelemetry-exporter-otlp, llama-index-legacy, llama-index-core, llama-parse, llama-index-vector-stores-mongodb, llama-index-storage-kvstore-mongodb, llama-index-readers-mongodb, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, arize-phoenix, llama-index-storage-index-store-mongodb, llama-index-storage-docstore-mongodb, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-callbacks-arize-phoenix, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib_metadata 7.0.2\n","    Uninstalling importlib_metadata-7.0.2:\n","      Successfully uninstalled importlib_metadata-7.0.2\n","  Attempting uninstall: cython\n","    Found existing installation: Cython 3.0.9\n","    Uninstalling Cython-3.0.9:\n","      Successfully uninstalled Cython-3.0.9\n","Successfully installed PyMuPDFb-1.23.22 arize-phoenix-3.13.1 bs4-0.0.2 cython-0.29.37 dataclasses-json-0.6.4 ddsketch-2.0.4 deprecated-1.2.14 dirtyjson-1.0.8 dnspython-2.6.1 graphql-core-3.2.3 h11-0.14.0 hdbscan-0.8.33 httpcore-1.0.4 httpx-0.27.0 importlib-metadata-6.11.0 install-1.3.5 llama-index-0.10.19 llama-index-agent-openai-0.1.5 llama-index-callbacks-arize-phoenix-0.1.4 llama-index-cli-0.1.9 llama-index-core-0.10.19 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.4 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.9 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.9 llama-index-readers-llama-parse-0.1.3 llama-index-readers-mongodb-0.1.3 llama-index-storage-docstore-mongodb-0.1.2 llama-index-storage-index-store-mongodb-0.1.2 llama-index-storage-kvstore-mongodb-0.1.2 llama-index-vector-stores-mongodb-0.1.4 llama-parse-0.3.9 llamaindex-py-client-0.1.13 marshmallow-3.21.1 mypy-extensions-1.0.0 openai-1.13.3 openinference-instrumentation-langchain-0.1.12 openinference-instrumentation-llama-index-1.2.0 openinference-instrumentation-openai-0.1.4 openinference-semantic-conventions-0.1.5 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-exporter-otlp-proto-http-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 pymongo-4.6.2 pymupdf-1.23.26 pynndescent-0.5.11 pypdf-4.1.0 starlette-0.37.2 strawberry-graphql-0.208.2 striprtf-0.0.26 tiktoken-0.6.0 typing-inspect-0.9.0 umap-learn-0.5.5 uvicorn-0.28.0\n"]}],"source":["!pip install llama-index-embeddings-openai arize-phoenix llama-index llama-index-callbacks-arize-phoenix pip install llama-index-vector-stores-mongodb llama-index-storage-docstore-mongodb llama-index-storage-index-store-mongodb llama-index-readers-mongodb \"openai>=1\" gcsfs nest-asyncio pymongo beautifulsoup4 certifi"]},{"cell_type":"code","execution_count":2,"id":"cf89f950-f074-45d7-81d4-b7d4d3158a37","metadata":{"id":"cf89f950-f074-45d7-81d4-b7d4d3158a37","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710360024156,"user_tz":420,"elapsed":40672,"user":{"displayName":"John Willis","userId":"15271974867993570949"}},"outputId":"4e8b573a-5b30-43b9-f1d7-11b305eb888a"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:phoenix.experimental.evals:Evals are moving out of experimental. Install the evals extra with `pip install arize-phoenix[evals]` and import `phoenix.evals`. For more info, see the [migration guide](https://github.com/Arize-ai/phoenix/blob/main/MIGRATION.md).\n"]}],"source":["import datetime\n","import json\n","import os\n","import pickle\n","import ssl\n","import time\n","import urllib\n","from getpass import getpass\n","from urllib.request import urlopen\n","\n","import certifi\n","import nest_asyncio\n","import openai\n","import pandas as pd\n","import phoenix as px\n","import requests\n","from bs4 import BeautifulSoup\n","from gcsfs import GCSFileSystem\n","from llama_index.core import (\n","    ServiceContext, StorageContext, download_loader,\n","    load_index_from_storage, set_global_handler\n",")\n","from llama_index.embeddings.openai import OpenAIEmbedding\n","from llama_index.core.graph_stores.simple import SimpleGraphStore\n","from llama_index.core.indices.vector_store.base import VectorStoreIndex\n","from llama_index.llms.openai import OpenAI\n","from llama_index.readers.mongodb import SimpleMongoReader\n","from llama_index.storage.docstore.mongodb import MongoDocumentStore\n","from llama_index.storage.index_store.mongodb import MongoIndexStore\n","from llama_index.vector_stores.mongodb import MongoDBAtlasVectorSearch\n","from phoenix.experimental.evals import (\n","    HallucinationEvaluator, OpenAIModel, QAEvaluator,\n","    RelevanceEvaluator, run_evals\n",")\n","from phoenix.session.evaluation import get_qa_with_reference, get_retrieved_documents\n","from phoenix.trace import DocumentEvaluations, SpanEvaluations\n","from pymongo.mongo_client import MongoClient\n","from pymongo.server_api import ServerApi\n","from tqdm import tqdm\n","\n","\n","nest_asyncio.apply()  # needed for concurrent evals in notebook environments\n","pd.set_option(\"display.max_colwidth\", 1000)"]},{"cell_type":"markdown","source":["## 2. Set up MongoDB Atlas\n","\n","To effectively use this notebook for MongoDB operations, it's essential to have a MongoDB account set up with a database and collection already created. Additionally, you need to have a vector index created as described in the MongoDB Atlas Search documentation.\n","\n","This can be done by following this steps:\n","\n","1. Create a MongoDB Atlas account.\n","2. Create a database.\n","3. Add a new collection to that database.\n","4. Create a search index with the following structure in the recently created collection:\n","\n","{\n","  \"fields\": [\n","    {\n","      \"numDimensions\": 1536,\n","      \"path\": \"embedding\",\n","      \"similarity\": \"euclidean\",\n","      \"type\": \"vector\"\n","    }\n","  ]\n","}\n","\n","\n","Whenever the set up is complete, you can check the connection to your notebook as shown below.\n","\n","*Note: You should add your ip address to the ip white list of your Mongo database in order to succesfuly connect.*"],"metadata":{"id":"xVBBk-SRKauo"},"id":"xVBBk-SRKauo"},{"cell_type":"code","execution_count":3,"id":"02258bb7-bf37-4173-8c28-6fb2d25d9680","metadata":{"id":"02258bb7-bf37-4173-8c28-6fb2d25d9680","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710363195410,"user_tz":420,"elapsed":1127,"user":{"displayName":"John Willis","userId":"15271974867993570949"}},"outputId":"f5d637c4-3374-4610-8f2e-90f772eb4aea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Pinged your deployment. You successfully connected to MongoDB!\n"]}],"source":["mongo_username = \"arize_mongo_read\"\n","mongo_password = \"phsW002Be9rEzjJd\"\n","\n","uri = f\"mongodb+srv://{mongo_username}:{mongo_password}@phoenix-llama.ywnxqjv.mongodb.net/?retryWrites=true&w=majority\"\n","\n","# Create a new client and connect to the server\n","client = MongoClient(uri)\n","\n","# Send a ping to confirm a successful connection\n","try:\n","    client.admin.command('ping')\n","    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n","except Exception as e:\n","    print(e)\n"]},{"cell_type":"markdown","source":["Now that the initial setup is complete, our next step involves generating and storing data in the newly created collection. The essential data elements required for each entry in the collection are 'text' and 'embedding'. The 'text' field should contain the textual information, while the 'embedding' field must store the corresponding vector representation. This structured approach ensures that each record in our collection is equipped with the necessary attributes for effective text search and vector-based operations."],"metadata":{"id":"Zq6kWB0JOnQ4"},"id":"Zq6kWB0JOnQ4"},{"cell_type":"code","execution_count":4,"id":"534df8f5-225d-4022-801a-4e935f1999dd","metadata":{"id":"534df8f5-225d-4022-801a-4e935f1999dd","executionInfo":{"status":"ok","timestamp":1710363205915,"user_tz":420,"elapsed":2136,"user":{"displayName":"John Willis","userId":"15271974867993570949"}}},"outputs":[],"source":["url = \"http://storage.googleapis.com/arize-assets/xander/milvus-workshop/milvus_dataset.json\"\n","\n","with urllib.request.urlopen(url) as response:\n","    buffer = response.read()\n","    data = json.loads(buffer.decode(\"utf-8\"))\n","    rows = data[\"rows\"]"]},{"cell_type":"markdown","source":["We then proceed to store data into our previously created collection."],"metadata":{"id":"GCdd5QkFnTSe"},"id":"GCdd5QkFnTSe"},{"cell_type":"code","execution_count":5,"id":"39dd567b-f6e7-4706-bce0-e69a7e42546e","metadata":{"id":"39dd567b-f6e7-4706-bce0-e69a7e42546e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710363216750,"user_tz":420,"elapsed":6605,"user":{"displayName":"John Willis","userId":"15271974867993570949"}},"outputId":"d02b9c0e-9304-4e4c-830c-17d9ef7c5f35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Succesfully added nodes into mongodb!\n"]}],"source":["db_name = 'phoenix'\n","collection_name = 'phoenix-docs'\n","\n","db = client[db_name]  # Replace with your database name\n","collection = db[collection_name]  # Replace with your collection name\n","\n","# Assuming 'overwrite=True' means you want to clear the collection first and insert nodes\n","overwrite=True\n","if overwrite:\n","    collection.delete_many({})\n","    nodes = []\n","    for row in rows:\n","        node = {\n","            \"embedding\": row[\"embedding\"],\n","            \"text\": row[\"text\"],\n","            \"id\": row[\"id\"],\n","            \"source_doc_id\": row[\"doc_id\"]  # Assuming this is a relationship reference\n","        }\n","        nodes.append(node)\n","\n","    # Insert the documents into MongoDB Atlas\n","    collection.insert_many(nodes)\n","    print(\"Succesfully added nodes into mongodb!\")"]},{"cell_type":"markdown","source":["## 3. Configure Your OpenAI API Key\n","\n","Set your OpenAI API key if it is not already set as an environment variable."],"metadata":{"id":"sCt7AW7yniQi"},"id":"sCt7AW7yniQi"},{"cell_type":"code","execution_count":6,"id":"52936831-26f8-4ad3-8e3c-0c8b74da72cc","metadata":{"id":"52936831-26f8-4ad3-8e3c-0c8b74da72cc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710363279679,"user_tz":420,"elapsed":32541,"user":{"displayName":"John Willis","userId":"15271974867993570949"}},"outputId":"c9e29a91-9362-4131-df15-0b121b580391"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Enter your OpenAI API key: 路路路路路路路路路路\n"]}],"source":["if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n","    openai_api_key = getpass(\" Enter your OpenAI API key: \")\n","openai.api_key = openai_api_key\n","os.environ[\"OPENAI_API_KEY\"] = openai_api_key"]},{"cell_type":"markdown","source":["## 4. Launch your phoenix application\n","\n","Enable Phoenix tracing within LlamaIndex by setting `arize_phoenix` as the global handler. This will mount Phoenix's [OpenInferenceTraceCallback](https://docs.arize.com/phoenix/integrations/llamaindex) as the global handler. Phoenix uses OpenInference traces - an open-source standard for capturing and storing LLM application traces that enables LLM applications to seamlessly integrate with LLM observability solutions such as Phoenix."],"metadata":{"id":"F46Fd3fboaIk"},"id":"F46Fd3fboaIk"},{"cell_type":"code","source":["session = px.launch_app()"],"metadata":{"id":"inBg-ABOOiyf","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1710363285047,"user_tz":420,"elapsed":1632,"user":{"displayName":"John Willis","userId":"15271974867993570949"}},"outputId":"d92d11c6-437f-4c70-9e33-e6147d69f9c7"},"id":"inBg-ABOOiyf","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":[" To view the Phoenix app in your browser, visit https://cpc0n4inik1-496ff2e9c6d22116-6006-colab.googleusercontent.com/\n"," To view the Phoenix app in a notebook, run `px.active_session().view()`\n"," For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"]}]},{"cell_type":"code","source":["set_global_handler(\"arize_phoenix\")"],"metadata":{"id":"FOzn_95tPijl","executionInfo":{"status":"ok","timestamp":1710363352847,"user_tz":420,"elapsed":228,"user":{"displayName":"John Willis","userId":"15271974867993570949"}}},"id":"FOzn_95tPijl","execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["This example uses a `MongoDBAtlasVectorSearch` and uses the previously generated collection to work fully connected with MongoDB but you can use whatever LlamaIndex application you like."],"metadata":{"id":"43rV8DPhos_K"},"id":"43rV8DPhos_K"},{"cell_type":"code","source":["db_name = 'phoenix' # Replace with your database name\n","collection_name = 'phoenix-docs' # Replace with your collection name\n","vector_index_name = 'vector_index' # Replace with your vector index name\n","\n","db = client[db_name]\n","collection = db[collection_name]\n","\n","mongo_username = \"YOUR_USERNAME\" # Replace mongo username\n","mongo_password = \"YOUR_PASSWORD\" # Replace mongo password\n","\n","# You can obtain your uri @... format directly in mongo atlas\n","uri = f\"mongodb+srv://{mongo_username}:{mongo_password}@phoenix-llama.ywnxqjv.mongodb.net/?retryWrites=true&w=majority\"\n","\n","query_dict = {}\n","reader = SimpleMongoReader(uri=uri)\n","documents = reader.load_data(\n","    db_name,\n","    collection_name,\n","    field_names=[\"text\"],\n","    query_dict=query_dict\n",")\n","\n","# Create a new client and connect to the server\n","client = MongoClient(uri, server_api=ServerApi('1'))\n","\n","# create Atlas as a vector store\n","store = MongoDBAtlasVectorSearch(\n","    client,\n","    db_name=db_name,\n","    collection_name=collection_name,\n","    index_name=vector_index_name\n",")\n","\n","storage_context = StorageContext.from_defaults(vector_store=store)\n","\n","service_context = ServiceContext.from_defaults(\n","    llm=OpenAI(model=\"gpt-4-1106-preview\", temperature=0.0),\n","    embed_model=OpenAIEmbedding(model=\"text-embedding-ada-002\"),\n",")\n","\n","index = VectorStoreIndex.from_documents(\n","    documents,\n","    storage_context=storage_context,\n","    service_context=service_context,\n","    show_progress=True\n",")\n"],"metadata":{"id":"IHqbRGn3u8r3","colab":{"base_uri":"https://localhost:8080/","height":169,"referenced_widgets":["9a03f93dbcec4891aead71937b40a75c","73a51e0b454147179635860eb4f734b6","eaed7a633e1147359ebd91907532f498","4373bc30752e41fb807d19df781f5520","6c25759a4f45421a9c976546d531be81","2b1f36577d914712953833bdbb50946d","34743207977b43a08b2bd03432a4690e","4c1753c93a544bcf885cf853d9cac8fa","e191a3f7c57f45c99fa99e6851e3ddfd","8b99dfa05d9945a4b0b8f77432e19592","2d4c37743df248e69fdaee67f569154e","c2b55245a6fd40d49dfb3c363cf59975","a59c79a2f6464dcea582848e6d0ac379","8dfc3373706e4d2192bb904df00ce7fd","d9443d16d0074247a76570441a134b12","f027e4cdd45e47feaaaa31a96b5715f0","d71d58a39f2a4280ba86e6a26476adb7","5454aa07445544b98bfeec83fd833833","5574ca616488473cb489aaef246a9530","b14551e2f05c40a3becb88008fd3524b","57ad881e1c68478498afa6d29ccdfc79","7c4a96a5adc04c80a1fd06d15add8b5a","91cd5873464d4ec3a250f18ef113eab6","9f20c2ccbf0c497fbe1fa16ef20ff45b","5bd99a915f594b0c893f991190515912","99adaddb99c84a88bc5d9751531c47b4","e09ccce10b7044b0ac10bab5be3b322e","f328dd4e95304694b4c4fe7eda920e8e","3535c67b78c046879fc623b66f18e224","a505e588f8954026b3d9d9ec4936f3c6","1ccd85299b99413481c850f6a9a56e6f","5a85caf39cb7410bab3529badcaa0e3a","64159b95a15e4a618c4b0252d8227f80"]},"executionInfo":{"status":"ok","timestamp":1710262633702,"user_tz":420,"elapsed":76312,"user":{"displayName":"Jason Lopatecki","userId":"09292015132620990027"}},"outputId":"f32978b3-5d99-48a5-8ced-f58543c97653"},"id":"IHqbRGn3u8r3","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-5459425d6d43>:36: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n","  service_context = ServiceContext.from_defaults(\n"]},{"output_type":"display_data","data":{"text/plain":["Parsing nodes:   0%|          | 0/2454 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a03f93dbcec4891aead71937b40a75c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2b55245a6fd40d49dfb3c363cf59975"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating embeddings:   0%|          | 0/312 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91cd5873464d4ec3a250f18ef113eab6"}},"metadata":{}}]},{"cell_type":"markdown","source":["## 5. Run Your Query Engine and View Your Traces in Phoenix\n","\n","We've compiled a list of commonly asked questions about Arize. Let's download the sample queries and take a look."],"metadata":{"id":"ieIoKLZoqxgq"},"id":"ieIoKLZoqxgq"},{"cell_type":"code","execution_count":null,"id":"19b9e13d-bf15-4e97-81f5-f80a69784c0c","metadata":{"id":"19b9e13d-bf15-4e97-81f5-f80a69784c0c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710262633895,"user_tz":420,"elapsed":195,"user":{"displayName":"Jason Lopatecki","userId":"09292015132620990027"}},"outputId":"8b8b1afd-5ea8-42eb-a721-1f9c111d34a5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['How do I use the SDK to upload a ranking model?',\n"," 'What drift metrics are supported in Arize?',\n"," 'Does Arize support batch models?',\n"," 'Does Arize support training data?',\n"," 'How do I configure a threshold if my data has seasonality trends?',\n"," 'How are clusters in the UMAP calculated? When are the clusters refreshed?',\n"," 'How does Arize calculate AUC?',\n"," 'Can I send truth labels to Arize separtely? ',\n"," 'How do I send embeddings to Arize?',\n"," 'Can I copy a dashboard']"]},"metadata":{},"execution_count":14}],"source":["queries_url = \"http://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/llm/context-retrieval/arize_docs_queries.jsonl\"\n","queries = []\n","with urlopen(queries_url) as response:\n","    for line in response:\n","        line = line.decode(\"utf-8\").strip()\n","        data = json.loads(line)\n","        queries.append(data[\"query\"])\n","queries[:10]"]},{"cell_type":"markdown","source":["Let's run the first 10 queries and view the traces in Phoenix.\n"],"metadata":{"id":"K-IzxjWf2TGn"},"id":"K-IzxjWf2TGn"},{"cell_type":"code","execution_count":null,"id":"1e1d0956-1508-4ab9-8af1-311943b636c2","metadata":{"id":"1e1d0956-1508-4ab9-8af1-311943b636c2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710262684668,"user_tz":420,"elapsed":50777,"user":{"displayName":"Jason Lopatecki","userId":"09292015132620990027"}},"outputId":"eeed5516-ab27-418c-b939-ef3c986d0e04"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|| 10/10 [00:50<00:00,  5.08s/it]\n"]}],"source":["query_engine = index.as_query_engine()\n","for query in tqdm(queries[:10]):\n","    try:\n","      query_engine.query(query)\n","    except Exception as e:\n","      pass"]},{"cell_type":"markdown","source":["And just for fun, ask your own question!"],"metadata":{"id":"ubv2u8fv2VPF"},"id":"ubv2u8fv2VPF"},{"cell_type":"code","source":["response = query_engine.query(\"What is Arize and how can it help me as an AI Engineer?\")\n","print(response)"],"metadata":{"id":"_lYAP38FSgGH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710262689573,"user_tz":420,"elapsed":4909,"user":{"displayName":"Jason Lopatecki","userId":"09292015132620990027"}},"outputId":"1b0d3204-3b3f-47d7-f409-3cc4573ab3a6"},"id":"_lYAP38FSgGH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Arize is a platform designed to assist AI Engineers and Machine Learning practitioners with various aspects of model lifecycle management. It provides tools to monitor model performance in real-time, even when there is a delay in receiving ground truth or feedback data. The platform aids in identifying and diagnosing the root causes of model failures or performance issues through tracing and explainability features. Additionally, it allows for the comparison of performance across multiple models. Arize also offers capabilities to detect and report on data drift, data quality issues, and potential model fairness or bias, which are critical for maintaining the integrity and effectiveness of AI systems. This suite of tools can help you ensure that your models perform optimally and responsibly after deployment.\n"]}]},{"cell_type":"markdown","source":["Check the Phoenix UI as your queries run. Your traces should appear in real time.\n","\n","Open the Phoenix UI with the link below if you haven't already and click through the queries to better understand how the query engine is performing. For each trace you will see a break\n","\n","Phoenix can be used to understand and troubleshoot your by surfacing:\n"," - **Application latency** - highlighting slow invocations of LLMs, Retrievers, etc.\n"," - **Token Usage** - Displays the breakdown of token usage with LLMs to surface up your most expensive LLM calls\n"," - **Runtime Exceptions** - Critical runtime exceptions such as rate-limiting are captured as exception events.\n"," - **Retrieved Documents** - view all the documents retrieved during a retriever call and the score and order in which they were returned\n"," - **Embeddings** - view the embedding text used for retrieval and the underlying embedding model\n","LLM Parameters - view the parameters used when calling out to an LLM to debug things like temperature and the system prompts\n"," - **Prompt Templates** - Figure out what prompt template is used during the prompting step and what variables were used.\n"," - **Tool Descriptions** - view the description and function signature of the tools your LLM has been given access to\n"," - **LLM Function Calls** - if using OpenAI or other a model with function calls, you can view the function selection and function messages in the input messages to the LLM.\n","\n","<img src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/images/RAG_trace_details.png\" alt=\"Trace Details View on Phoenix\" style=\"width:100%; height:auto;\">"],"metadata":{"id":"Xhaf9CVY2Yy7"},"id":"Xhaf9CVY2Yy7"},{"cell_type":"code","execution_count":null,"id":"ffe25cbe-b1a5-4611-b604-82f1f02738c3","metadata":{"id":"ffe25cbe-b1a5-4611-b604-82f1f02738c3","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1710262705874,"user_tz":420,"elapsed":1213,"user":{"displayName":"Jason Lopatecki","userId":"09292015132620990027"}},"outputId":"1b321836-3693-4fc7-9a4b-43a9a4fbab93"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Open the Phoenix UI if you haven't already: https://x4b27ifweub2-496ff2e9c6d22116-6006-colab.googleusercontent.com/\n"]}],"source":["print(f\" Open the Phoenix UI if you haven't already: {session.url}\")"]},{"cell_type":"markdown","source":["## 6. Export and Evaluate Your Trace Data\n","You can export your trace data as a pandas dataframe for further analysis and evaluation.\n","\n","In this case, we will export our retriever spans into two separate dataframes:\n","\n","queries_df, in which the retrieved documents for each query are concatenated into a single column,\n","retrieved_documents_df, in which each retrieved document is \"exploded\" into its own row to enable the evaluation of each query-document pair in isolation.\n","This will enable us to compute multiple kinds of evaluations, including:\n","\n","relevance: Are the retrieved documents grounded in the response?\n","Q&A correctness: Are your application's responses grounded in the retrieved context?\n","hallucinations: Is your application making up false information?"],"metadata":{"id":"c0zHq7Pp2hnx"},"id":"c0zHq7Pp2hnx"},{"cell_type":"code","execution_count":null,"id":"b42c0869-f7f7-4fb4-90d3-8e93a18bf1a9","metadata":{"id":"b42c0869-f7f7-4fb4-90d3-8e93a18bf1a9"},"outputs":[],"source":["queries_df = get_qa_with_reference(session)\n","retrieved_documents_df = get_retrieved_documents(session)"]},{"cell_type":"markdown","source":["Next, define your evaluation model and your evaluators.\n","\n","Evaluators are built on top of language models and prompt the LLM to assess the quality of responses, the relevance of retrieved documents, etc., and provide a quality signal even in the absence of human-labeled data. Pick an evaluator type and instantiate it with the language model you want to use to perform evaluations using our battle-tested evaluation templates."],"metadata":{"id":"BGqH0E_J2lx8"},"id":"BGqH0E_J2lx8"},{"cell_type":"code","source":["eval_model = OpenAIModel(\n","    model_name=\"gpt-4-1106-preview\",\n",")\n","hallucination_evaluator = HallucinationEvaluator(eval_model)\n","qa_correctness_evaluator = QAEvaluator(eval_model)\n","relevance_evaluator = RelevanceEvaluator(eval_model)\n","\n","hallucination_eval_df, qa_correctness_eval_df = run_evals(\n","    dataframe=queries_df,\n","    evaluators=[hallucination_evaluator, qa_correctness_evaluator],\n","    provide_explanation=True,\n",")\n","relevance_eval_df = run_evals(\n","    dataframe=retrieved_documents_df,\n","    evaluators=[relevance_evaluator],\n","    provide_explanation=True,\n",")[0]\n","\n","px.log_evaluations(\n","    SpanEvaluations(eval_name=\"Hallucination\", dataframe=hallucination_eval_df),\n","    SpanEvaluations(eval_name=\"QA Correctness\", dataframe=qa_correctness_eval_df),\n",")\n","px.log_evaluations(DocumentEvaluations(eval_name=\"Relevance\", dataframe=relevance_eval_df))"],"metadata":{"id":"zJzLSmP6mp1o","colab":{"base_uri":"https://localhost:8080/","height":135,"referenced_widgets":["2bbbeb04254641b6922e27da2dcac17b","de568a23532d455ea889e287dd923336","6d0a982b0021472bb774502a6fcd1259","70943da6980a4ea3a8363bf1b34598b4","0b6986edefbd46e286100d89cdd22abd","4383bdb9af72486ea3db8125dd59db25","e099487f9c72427e8b45572bef952194","b087311c4a2e4d1ba59890171f1ea70f","4084890029f5408f849d0aab0a277f92","c3a8cf336dab49688b578d8f4666523e","e7d545c86320458db365965a584f5325","815c8db5f76e4071855c97f778728623","0aeb21a9b10249639f42d04a43dc4ffa","3c9281a65acf4266bf67ab52a7c122c2","685a08d86cf948cd808097c525c368c8","3721a78c3ba0442abf4bf60fb98f458e","2334908d712442e69d2354d175ccbb87","88e4b352e79b40c7be4f4a99cba94ee2","05eda7b69cb247b7b5d0cf0372f94d65","eb3c72af6ad941af9c353fba0dad9a33","6b69dc758a0743c7a6da7d5fce44bf21","b42ba2740d7a4275b3e7cd4bb5875dc1"]},"executionInfo":{"status":"ok","timestamp":1710262746425,"user_tz":420,"elapsed":39113,"user":{"displayName":"Jason Lopatecki","userId":"09292015132620990027"}},"outputId":"0a8318d6-66b0-4d81-a932-233351fa9af4"},"id":"zJzLSmP6mp1o","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The `model_name` field is deprecated. Use `model` instead.                 This will be removed in a future release.\n"]},{"output_type":"display_data","data":{"text/plain":["run_evals |          | 0/20 (0.0%) |  00:00<? | ?it/s"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bbbeb04254641b6922e27da2dcac17b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["run_evals |          | 0/10 (0.0%) |  00:00<? | ?it/s"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"815c8db5f76e4071855c97f778728623"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:phoenix.session.evaluation:This `log_evaluations` function is deprecated and will be removed in a future release. Please use `px.Client().log_evaluations(*evaluations)` instead.\n","WARNING:phoenix.session.evaluation:This `log_evaluations` function is deprecated and will be removed in a future release. Please use `px.Client().log_evaluations(*evaluations)` instead.\n"]}]},{"cell_type":"markdown","source":["Your evaluations should now appear as annotations on the appropriate spans in Phoenix.\n","\n","![A view of the Phoenix UI with evaluation annotations](https://storage.googleapis.com/arize-assets/phoenix/assets/docs/notebooks/evals/traces_with_evaluation_annotations.png)"],"metadata":{"id":"s4C3S4Bd2rE_"},"id":"s4C3S4Bd2rE_"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"colab":{"provenance":[{"file_id":"1LXJW0YS-N8_5f6E6p1hGGLsZ2k4ZD5P3","timestamp":1710359641465},{"file_id":"1G3k2vIOTHAQEctIQj5sU0FWOWYpXnH2x","timestamp":1710261382985},{"file_id":"12EmDpnof1VITRWwsHLM2oijmYb4Qtj26","timestamp":1710174254798},{"file_id":"1BFAEbqJoax0BIKuMls_thCjw2KqI6ZUe","timestamp":1706077055600}]},"widgets":{"application/vnd.jupyter.widget-state+json":{"9a03f93dbcec4891aead71937b40a75c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73a51e0b454147179635860eb4f734b6","IPY_MODEL_eaed7a633e1147359ebd91907532f498","IPY_MODEL_4373bc30752e41fb807d19df781f5520"],"layout":"IPY_MODEL_6c25759a4f45421a9c976546d531be81"}},"73a51e0b454147179635860eb4f734b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b1f36577d914712953833bdbb50946d","placeholder":"","style":"IPY_MODEL_34743207977b43a08b2bd03432a4690e","value":"Parsingnodes:100%"}},"eaed7a633e1147359ebd91907532f498":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c1753c93a544bcf885cf853d9cac8fa","max":2454,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e191a3f7c57f45c99fa99e6851e3ddfd","value":2454}},"4373bc30752e41fb807d19df781f5520":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b99dfa05d9945a4b0b8f77432e19592","placeholder":"","style":"IPY_MODEL_2d4c37743df248e69fdaee67f569154e","value":"2454/2454[00:14&lt;00:00,188.05it/s]"}},"6c25759a4f45421a9c976546d531be81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b1f36577d914712953833bdbb50946d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34743207977b43a08b2bd03432a4690e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c1753c93a544bcf885cf853d9cac8fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e191a3f7c57f45c99fa99e6851e3ddfd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b99dfa05d9945a4b0b8f77432e19592":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d4c37743df248e69fdaee67f569154e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2b55245a6fd40d49dfb3c363cf59975":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a59c79a2f6464dcea582848e6d0ac379","IPY_MODEL_8dfc3373706e4d2192bb904df00ce7fd","IPY_MODEL_d9443d16d0074247a76570441a134b12"],"layout":"IPY_MODEL_f027e4cdd45e47feaaaa31a96b5715f0"}},"a59c79a2f6464dcea582848e6d0ac379":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d71d58a39f2a4280ba86e6a26476adb7","placeholder":"","style":"IPY_MODEL_5454aa07445544b98bfeec83fd833833","value":"Generatingembeddings:100%"}},"8dfc3373706e4d2192bb904df00ce7fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5574ca616488473cb489aaef246a9530","max":2048,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b14551e2f05c40a3becb88008fd3524b","value":2048}},"d9443d16d0074247a76570441a134b12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57ad881e1c68478498afa6d29ccdfc79","placeholder":"","style":"IPY_MODEL_7c4a96a5adc04c80a1fd06d15add8b5a","value":"2048/2048[00:30&lt;00:00,64.78it/s]"}},"f027e4cdd45e47feaaaa31a96b5715f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d71d58a39f2a4280ba86e6a26476adb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5454aa07445544b98bfeec83fd833833":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5574ca616488473cb489aaef246a9530":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b14551e2f05c40a3becb88008fd3524b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"57ad881e1c68478498afa6d29ccdfc79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c4a96a5adc04c80a1fd06d15add8b5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91cd5873464d4ec3a250f18ef113eab6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f20c2ccbf0c497fbe1fa16ef20ff45b","IPY_MODEL_5bd99a915f594b0c893f991190515912","IPY_MODEL_99adaddb99c84a88bc5d9751531c47b4"],"layout":"IPY_MODEL_e09ccce10b7044b0ac10bab5be3b322e"}},"9f20c2ccbf0c497fbe1fa16ef20ff45b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f328dd4e95304694b4c4fe7eda920e8e","placeholder":"","style":"IPY_MODEL_3535c67b78c046879fc623b66f18e224","value":"Generatingembeddings:100%"}},"5bd99a915f594b0c893f991190515912":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a505e588f8954026b3d9d9ec4936f3c6","max":312,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ccd85299b99413481c850f6a9a56e6f","value":312}},"99adaddb99c84a88bc5d9751531c47b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a85caf39cb7410bab3529badcaa0e3a","placeholder":"","style":"IPY_MODEL_64159b95a15e4a618c4b0252d8227f80","value":"312/312[00:05&lt;00:00,45.14it/s]"}},"e09ccce10b7044b0ac10bab5be3b322e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f328dd4e95304694b4c4fe7eda920e8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3535c67b78c046879fc623b66f18e224":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a505e588f8954026b3d9d9ec4936f3c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ccd85299b99413481c850f6a9a56e6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a85caf39cb7410bab3529badcaa0e3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64159b95a15e4a618c4b0252d8227f80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bbbeb04254641b6922e27da2dcac17b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de568a23532d455ea889e287dd923336","IPY_MODEL_6d0a982b0021472bb774502a6fcd1259","IPY_MODEL_70943da6980a4ea3a8363bf1b34598b4"],"layout":"IPY_MODEL_0b6986edefbd46e286100d89cdd22abd"}},"de568a23532d455ea889e287dd923336":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4383bdb9af72486ea3db8125dd59db25","placeholder":"","style":"IPY_MODEL_e099487f9c72427e8b45572bef952194","value":"run_evals"}},"6d0a982b0021472bb774502a6fcd1259":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b087311c4a2e4d1ba59890171f1ea70f","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4084890029f5408f849d0aab0a277f92","value":20}},"70943da6980a4ea3a8363bf1b34598b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3a8cf336dab49688b578d8f4666523e","placeholder":"","style":"IPY_MODEL_e7d545c86320458db365965a584f5325","value":"20/20(100.0%)|斥00:26&lt;00:00|3.75s/it"}},"0b6986edefbd46e286100d89cdd22abd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4383bdb9af72486ea3db8125dd59db25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e099487f9c72427e8b45572bef952194":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b087311c4a2e4d1ba59890171f1ea70f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4084890029f5408f849d0aab0a277f92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3a8cf336dab49688b578d8f4666523e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7d545c86320458db365965a584f5325":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"815c8db5f76e4071855c97f778728623":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0aeb21a9b10249639f42d04a43dc4ffa","IPY_MODEL_3c9281a65acf4266bf67ab52a7c122c2","IPY_MODEL_685a08d86cf948cd808097c525c368c8"],"layout":"IPY_MODEL_3721a78c3ba0442abf4bf60fb98f458e"}},"0aeb21a9b10249639f42d04a43dc4ffa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2334908d712442e69d2354d175ccbb87","placeholder":"","style":"IPY_MODEL_88e4b352e79b40c7be4f4a99cba94ee2","value":"run_evals"}},"3c9281a65acf4266bf67ab52a7c122c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_05eda7b69cb247b7b5d0cf0372f94d65","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb3c72af6ad941af9c353fba0dad9a33","value":10}},"685a08d86cf948cd808097c525c368c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b69dc758a0743c7a6da7d5fce44bf21","placeholder":"","style":"IPY_MODEL_b42ba2740d7a4275b3e7cd4bb5875dc1","value":"10/10(100.0%)|斥00:10&lt;00:00|1.35it/s"}},"3721a78c3ba0442abf4bf60fb98f458e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2334908d712442e69d2354d175ccbb87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88e4b352e79b40c7be4f4a99cba94ee2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05eda7b69cb247b7b5d0cf0372f94d65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb3c72af6ad941af9c353fba0dad9a33":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b69dc758a0743c7a6da7d5fce44bf21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b42ba2740d7a4275b3e7cd4bb5875dc1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}